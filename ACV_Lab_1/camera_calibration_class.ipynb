{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb4a8f4",
   "metadata": {},
   "source": [
    "# Applied Computer Vision (ACV)\n",
    "\n",
    "## Lab 1 - January 16th, 2026\n",
    "\n",
    "### Camera Calibration & Projection + OpenCV Primer\n",
    "\n",
    "\n",
    "# Camera Calibration with OpenCV: A Complete Guide\n",
    "\n",
    "\n",
    "This notebook will guide you and your class through the concepts and practical steps of camera calibration using OpenCV. We'll cover:\n",
    "- What camera calibration is and why it's important\n",
    "- How to capture calibration images\n",
    "- How calibration is computed\n",
    "- How to use the results\n",
    "- A primer on OpenCV basics for beginners\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is Camera Calibration?\n",
    "\n",
    "**Camera calibration** is the process of determining the internal characteristics (intrinsic parameters) and lens distortion of a camera. This is essential for:\n",
    "- Correcting lens distortion (straight lines appear curved in raw images)\n",
    "- Mapping 3D real-world points to 2D image points accurately\n",
    "- Enabling precise measurements, 3D reconstruction, and robotics\n",
    "\n",
    "### Why do we need calibration?\n",
    "- Real-world cameras are not perfect pinhole cameras. Lenses introduce distortion.\n",
    "- Calibration finds the camera matrix (focal length, principal point) and distortion coefficients.\n",
    "\n",
    "### The Pinhole Camera Model\n",
    "The relationship between a 3D point $(X, Y, Z)$ and its image projection $(x, y)$ is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} = K \\cdot [R|t] \\cdot \\begin{bmatrix} X \\\\ Y \\\\ Z \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $K$ is the camera matrix, $[R|t]$ is the rotation and translation (extrinsics).\n",
    "\n",
    "#### Exploding the Matrices\n",
    "- **Camera Matrix $K$ (Intrinsics):**\n",
    "  - $K$ is a $3 \\times 3$ matrix that contains the intrinsic parameters of the camera:\n",
    "    $$\n",
    "    K = \\begin{bmatrix}\n",
    "      f_x & s & c_x \\\\\n",
    "      0 & f_y & c_y \\\\\n",
    "      0 & 0 & 1\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "    - $f_x, f_y$: Focal lengths in pixels (can differ for non-square pixels)\n",
    "    - $s$: Skew (usually 0, unless the sensor axes are not perpendicular)\n",
    "    - $c_x, c_y$: Principal point (usually near the image center)\n",
    "- **$[R|t]$ (Extrinsics):**\n",
    "  - $R$ is a $3 \\times 3$ rotation matrix (orientation of the camera)\n",
    "  - $t$ is a $3 \\times 1$ translation vector (position of the camera)\n",
    "  - Together, $[R|t]$ transforms 3D world coordinates to the camera's coordinate system.\n",
    "\n",
    "### Lens Distortion\n",
    "- **Radial distortion:** Straight lines appear curved (barrel or pincushion)\n",
    "- **Tangential distortion:** Image appears slanted if lens is not parallel to sensor\n",
    "\n",
    "*You can visualize these distortions with the images below (add your own for radial and tangential distortion):*\n",
    "\n",
    "---\n",
    "\n",
    "### Perspective Projection Visualizations\n",
    "\n",
    "<img src=\"notebook_images/perspective_projection_offset.png\" alt=\"Perspective Projection Offset\" width=\"600\"/>\n",
    "\n",
    "<img src=\"notebook_images/perspective_projection_equation.png\" alt=\"Perspective Projection Equation\" width=\"600\"/>\n",
    "\n",
    "- To ensure positive pixel coordinates, a **principal point offset** $c$ is usually added.\n",
    "- This moves the image coordinate system to the corner of the image plane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2213783",
   "metadata": {},
   "source": [
    "## 2. Understanding Chessboard Patterns for Calibration\n",
    "\n",
    "- **Why chessboards?**\n",
    "  - Chessboard patterns provide a regular grid of high-contrast corners that are easy for algorithms to detect.\n",
    "  - The known geometry (spacing and number of inner corners) allows us to relate 3D world points to 2D image points.\n",
    "\n",
    "- **What are \"inner corners\"?**\n",
    "  - Inner corners are the intersections inside the chessboard, not the squares themselves.\n",
    "  - For a 9x7 chessboard, there are 9 columns and 7 rows of inner corners (so 63 total corners).\n",
    "\n",
    "- **How does this help calibration?**\n",
    "  - For each image, we know where each corner is in 3D (on the chessboard) and where it appears in the image (2D).\n",
    "  - This correspondence is the foundation for solving the camera parameters.\n",
    "\n",
    "**Diagram:**\n",
    "\n",
    "|  |  |  |  |  |  |  |  |  |\n",
    "|--|--|--|--|--|--|--|--|--|\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "|● |● |● |● |● |● |● |● |● |\n",
    "\n",
    "(Each ● is an inner corner for a 9x7 pattern)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d252f89",
   "metadata": {},
   "source": [
    "## 3. Capturing Calibration Images with OpenCV\n",
    "\n",
    "To calibrate a camera, you need several images of a chessboard pattern taken from different angles and positions.\n",
    "\n",
    "**Tips for capturing good calibration images:**\n",
    "- Use at least 10-20 images for best results\n",
    "- Vary the angle, distance, and orientation of the chessboard\n",
    "- Ensure the chessboard is flat and fully visible in each image\n",
    "- Avoid glare, shadows, and motion blur\n",
    "- Use good lighting\n",
    "\n",
    "**What happens during capture:**\n",
    "- The script shows a live camera feed\n",
    "- When the chessboard is detected, you can press SPACE to save the image\n",
    "- The script saves images to a folder for later calibration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c1469",
   "metadata": {},
   "source": [
    "## 4. Exploring the Image Capture Script\n",
    "\n",
    "Let's break down the `capture.py` script used for collecting calibration images:\n",
    "\n",
    "**Key steps:**\n",
    "1. **Set parameters:**\n",
    "   - Save directory, number of images, chessboard size, camera index\n",
    "2. **Open the camera:**\n",
    "   - Uses `cv2.VideoCapture` to access the webcam\n",
    "3. **Detect chessboard corners:**\n",
    "   - Converts each frame to grayscale\n",
    "   - Uses `cv2.findChessboardCorners` to find the pattern\n",
    "   - If found, draws corners with `cv2.drawChessboardCorners`\n",
    "4. **User controls:**\n",
    "   - Press SPACE to save an image when the chessboard is detected\n",
    "   - Press ESC to exit\n",
    "5. **Save images:**\n",
    "   - Images are saved to the specified directory for calibration\n",
    "\n",
    "**Example code snippet:**\n",
    "```python\n",
    "found, corners = cv2.findChessboardCorners(gray, CHESSBOARD_SIZE, None)\n",
    "if found:\n",
    "    cv2.drawChessboardCorners(display, CHESSBOARD_SIZE, corners, found)\n",
    "    # ...\n",
    "```\n",
    "\n",
    "**What to watch for:**\n",
    "- Only save images when the chessboard is detected (green corners appear)\n",
    "- Try to capture a variety of angles and positions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb529ad",
   "metadata": {},
   "source": [
    "## 5. Basics of OpenCV: A Primer\n",
    "\n",
    "\n",
    "OpenCV is a powerful library for computer vision and image processing. Here are some basics to get you started, in a recommended learning sequence:\n",
    "\n",
    "\n",
    "### 1. Reading and Displaying Images\n",
    "```python\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "print('Image shape:', img.shape)  # (height, width, channels)\n",
    "print('Pixel value at (100, 100):', img[100, 100])\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "### 2. Viewing Pixel Values and Image Shape\n",
    "```python\n",
    "print('Image shape:', img.shape)  # (height, width, channels)\n",
    "print('Pixel at (50, 50):', img[50, 50])  # [B, G, R] values\n",
    "```\n",
    "\n",
    "\n",
    "### 3. Saving Images\n",
    "```python\n",
    "cv2.imwrite('output.jpg', img)\n",
    "```\n",
    "\n",
    "\n",
    "### 4. Converting to Grayscale\n",
    "```python\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Grayscale', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "### 5. Drawing on Images\n",
    "```python\n",
    "cv2.rectangle(img, (50, 50), (200, 200), (0, 255, 0), 2)  # Draw a green rectangle\n",
    "cv2.circle(img, (100, 100), 40, (255, 0, 0), -1)           # Draw a filled blue circle\n",
    "cv2.imshow('Drawn Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "### 6. Reading Video Files\n",
    "```python\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # ESC to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "### 7. Reading from Webcam or USB Camera\n",
    "```python\n",
    "cap = cv2.VideoCapture(0)  # 0 for default webcam, 1/2/... for USB cameras\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "### 8. Basic Image Processing\n",
    "```python\n",
    "# Thresholding\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Show results\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732c916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1eb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Reading and displaying an image\n",
    "import cv2\n",
    "img = cv2.imread('calib_images\\img_00.jpg')\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe72f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (480, 640, 3)\n",
      "Pixel at (50, 50): [20 26 21]\n"
     ]
    }
   ],
   "source": [
    "# Practice: Viewing pixel values and image shape\n",
    "import cv2\n",
    "img = cv2.imread('img_00.jpg')\n",
    "print('Image shape:', img.shape)  # (height, width, channels)\n",
    "print('Pixel at (50, 50):', img[50, 50])  # [B, G, R] values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ec560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Converting to grayscale\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Grayscale', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Drawing on images\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "cv2.rectangle(img, (50, 50), (200, 200), (0, 255, 0), 2)  # Green rectangle\n",
    "cv2.circle(img, (100, 100), 40, (255, 0, 0), -1)           # Filled blue circle\n",
    "cv2.imshow('Drawn Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37078239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Saving an image\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "cv2.imwrite('output.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Reading from webcam or USB camera\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)  # 0 for default webcam, 1/2/... for USB cameras\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Reading a video file\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # ESC to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11571494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Basic image processing (thresholding and edge detection)\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Thresholding\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "# Edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "# Show results\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e100b0",
   "metadata": {},
   "source": [
    "## 6. How Camera Calibration is Computed\n",
    "\n",
    "Camera calibration is a mathematical process that finds the camera's intrinsic parameters and lens distortion.\n",
    "\n",
    "### Steps:\n",
    "1. **Collect object points:**\n",
    "   - The 3D coordinates of the chessboard corners (in real-world units, e.g., millimeters)\n",
    "2. **Collect image points:**\n",
    "   - The 2D pixel coordinates where those corners appear in each image\n",
    "3. **Run calibration:**\n",
    "   - Use `cv2.calibrateCamera` to solve for the camera matrix and distortion coefficients\n",
    "\n",
    "### The Camera Matrix (Intrinsics)\n",
    "$$\n",
    "K = \\begin{bmatrix}\n",
    "  f_x & 0 & c_x \\\\\n",
    "  0 & f_y & c_y \\\\\n",
    "  0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- $f_x, f_y$: Focal lengths (in pixels)\n",
    "- $c_x, c_y$: Principal point (optical center)\n",
    "\n",
    "### Distortion Coefficients\n",
    "- $k_1, k_2, k_3$: Radial distortion\n",
    "- $p_1, p_2$: Tangential distortion\n",
    "\n",
    "### The Calibration Equation\n",
    "$$\n",
    "\\text{image point} = \\text{project}(K, \\text{distortion}, R, t, \\text{object point})\n",
    "$$\n",
    "Where $R$ and $t$ are the rotation and translation for each image.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d5f2d",
   "metadata": {},
   "source": [
    "## 7. Exploring the Calibration Script\n",
    "\n",
    "Let's walk through the `calibrate.py` script:\n",
    "\n",
    "**Key steps:**\n",
    "1. **Set parameters:**\n",
    "   - Chessboard size, square size, image directory, output file\n",
    "2. **Prepare object points:**\n",
    "   - Create a 3D grid of chessboard corners in real-world units\n",
    "3. **Load images:**\n",
    "   - Find all `.jpg` images in the calibration folder\n",
    "4. **Detect and refine corners:**\n",
    "   - For each image, detect chessboard corners with `cv2.findChessboardCorners`\n",
    "   - Refine corner locations to subpixel accuracy with `cv2.cornerSubPix`\n",
    "5. **Collect points:**\n",
    "   - Store 3D object points and 2D image points for each successful detection\n",
    "6. **Run calibration:**\n",
    "   - Use `cv2.calibrateCamera` to compute the camera matrix and distortion\n",
    "7. **Assess quality:**\n",
    "   - Print the reprojection error and interpret the results\n",
    "8. **Save results:**\n",
    "   - Store the calibration data in a YAML file for later use\n",
    "\n",
    "**Error handling:**\n",
    "- The script checks for missing images, failed detections, and calibration errors, and provides helpful messages.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fc05b",
   "metadata": {},
   "source": [
    "## 8. Saving and Using Calibration Parameters\n",
    "\n",
    "After calibration, the camera matrix and distortion coefficients are saved to a file (e.g., `calibration.yaml`).\n",
    "\n",
    "**How to load and use these parameters:**\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# Load calibration data\n",
    "with open('calibration.yaml') as f:\n",
    "    calib = yaml.safe_load(f)\n",
    "    mtx = np.array(calib['camera_matrix'])\n",
    "    dist = np.array(calib['dist_coeff'])\n",
    "\n",
    "# Undistort an image\n",
    "img = cv2.imread('test_image.jpg')\n",
    "undistorted = cv2.undistort(img, mtx, dist)\n",
    "cv2.imshow('Undistorted', undistorted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "**Applications:**\n",
    "- Undistorting images for measurement or further processing\n",
    "- Accurate 3D reconstruction\n",
    "- Robotics and augmented reality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9395585",
   "metadata": {},
   "source": [
    "## ArUco Marker Pose Detection: Code Walkthrough and Concepts\n",
    "\n",
    "### What is \"Pose\"?\n",
    "- In computer vision, the **pose** of an object means its position and orientation in 3D space relative to the camera.\n",
    "- For a marker, this is usually given as:\n",
    "  - **Translation vector (tvec):** X, Y, Z position (in meters) from the camera.\n",
    "  - **Rotation vector (rvec):** Orientation, often as axis-angle, Euler angles, or a rotation matrix.\n",
    "- Knowing the pose allows you to overlay graphics (augmented reality), localize robots, or measure real-world distances.\n",
    "\n",
    "### How ArUco Pose Detection Works\n",
    "1. **Camera Calibration**:\n",
    "   - Loads the camera matrix and distortion coefficients from a YAML file (from your calibration step).\n",
    "2. **ArUco Marker Detection**:\n",
    "   - Uses OpenCV's ArUco module to detect markers in the video frame.\n",
    "   - Finds the 2D image coordinates of the marker corners.\n",
    "3. **Pose Estimation**:\n",
    "   - Knows the real-world size and 3D coordinates of the marker corners.\n",
    "   - Uses `cv2.solvePnP` to compute the marker's pose (rvec, tvec) from the 2D-3D correspondences.\n",
    "   - Draws axes on the marker to visualize orientation.\n",
    "4. **Display**:\n",
    "   - Shows the marker ID, distance, position (X, Y, Z), and rotation (roll, pitch, yaw) on the video.\n",
    "\n",
    "### Code Walkthrough\n",
    "- **Imports and Config**: Loads OpenCV, numpy, yaml, and sets marker size, dictionary, and calibration file.\n",
    "- **Calibration Load**: Reads camera intrinsics and distortion from YAML.\n",
    "- **ArUco Detector**: Sets up the ArUco dictionary and detector parameters.\n",
    "- **Marker 3D Points**: Defines the real-world coordinates of the marker corners (centered at (0,0,0)).\n",
    "- **Video Capture**: Opens the webcam.\n",
    "- **Main Loop**:\n",
    "  - Reads a frame, detects markers.\n",
    "  - For each detected marker:\n",
    "    - Finds its corners in the image.\n",
    "    - Calls `cv2.solvePnP` to estimate pose.\n",
    "    - Draws axes and overlays pose info.\n",
    "    - Optionally prints detailed pose to terminal.\n",
    "  - If no marker is found, displays a warning.\n",
    "- **Rotation Conversion**: Converts the rotation vector to roll, pitch, yaw (Euler angles) for easier interpretation.\n",
    "- **Controls**: ESC/Q to quit, P to print pose details.\n",
    "\n",
    "### Key Functions\n",
    "- `cv2.aruco.ArucoDetector`: Detects ArUco markers in the image.\n",
    "- `cv2.solvePnP`: Computes the pose of the marker from 2D-3D correspondences.\n",
    "- `cv2.drawFrameAxes`: Draws the 3D axes on the marker.\n",
    "\n",
    "### Example Output\n",
    "- **Position (X, Y, Z):** Where the marker is in meters relative to the camera.\n",
    "- **Rotation (Roll, Pitch, Yaw):** How the marker is oriented.\n",
    "- **Axes Colors:** X (red), Y (green), Z (blue).\n",
    "\n",
    "**Generate your own ArUco markers here:** [https://chev.me/arucogen/](https://chev.me/arucogen/)\n",
    "\n",
    "This technique is widely used in robotics, AR, and camera localization!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
